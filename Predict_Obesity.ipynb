{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM96MJqZ3W8t2VrDj4LVygp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shilpathota/AI_ML/blob/master/Predict_Obesity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwF3KMOg6KBx",
        "outputId": "bb9e8b15-49b4-435f-b341-c9bf3166cb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Importing the dataset\n",
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features\n",
        "y = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets\n",
        "\n",
        "# metadata\n",
        "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.metadata)\n",
        "\n",
        "# variable information\n",
        "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWH_55vM9PAE",
        "outputId": "2404b8ec-f358-47ca-d715-e42e9e35d832"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 544, 'name': 'Estimation of Obesity Levels Based On Eating Habits and Physical Condition ', 'repository_url': 'https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition', 'data_url': 'https://archive.ics.uci.edu/static/public/544/data.csv', 'abstract': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. ', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 2111, 'num_features': 16, 'feature_types': ['Integer'], 'demographics': ['Gender', 'Age'], 'target_col': ['NObeyesdad'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2019, 'last_updated': 'Tue Sep 10 2024', 'dataset_doi': '10.24432/C5H31Z', 'creators': [], 'intro_paper': {'ID': 358, 'type': 'NATIVE', 'title': 'Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico', 'authors': 'Fabio Mendoza Palechor, Alexis De la Hoz Manotas', 'venue': 'Data in Brief', 'year': 2019, 'journal': None, 'DOI': '10.1016/j.dib.2019.104344', 'URL': 'https://www.semanticscholar.org/paper/35b40bacd2ffa9370885b7a3004d88995fd1d011', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Read the article (https://doi.org/10.1016/j.dib.2019.104344) to see the description of the attributes.', 'citation': None}}\n",
            "                              name     role         type demographic  \\\n",
            "0                           Gender  Feature  Categorical      Gender   \n",
            "1                              Age  Feature   Continuous         Age   \n",
            "2                           Height  Feature   Continuous        None   \n",
            "3                           Weight  Feature   Continuous        None   \n",
            "4   family_history_with_overweight  Feature       Binary        None   \n",
            "5                             FAVC  Feature       Binary        None   \n",
            "6                             FCVC  Feature      Integer        None   \n",
            "7                              NCP  Feature   Continuous        None   \n",
            "8                             CAEC  Feature  Categorical        None   \n",
            "9                            SMOKE  Feature       Binary        None   \n",
            "10                            CH2O  Feature   Continuous        None   \n",
            "11                             SCC  Feature       Binary        None   \n",
            "12                             FAF  Feature   Continuous        None   \n",
            "13                             TUE  Feature      Integer        None   \n",
            "14                            CALC  Feature  Categorical        None   \n",
            "15                          MTRANS  Feature  Categorical        None   \n",
            "16                      NObeyesdad   Target  Categorical        None   \n",
            "\n",
            "                                          description units missing_values  \n",
            "0                                                None  None             no  \n",
            "1                                                None  None             no  \n",
            "2                                                None  None             no  \n",
            "3                                                None  None             no  \n",
            "4   Has a family member suffered or suffers from o...  None             no  \n",
            "5            Do you eat high caloric food frequently?  None             no  \n",
            "6        Do you usually eat vegetables in your meals?  None             no  \n",
            "7              How many main meals do you have daily?  None             no  \n",
            "8                  Do you eat any food between meals?  None             no  \n",
            "9                                       Do you smoke?  None             no  \n",
            "10                 How much water do you drink daily?  None             no  \n",
            "11         Do you monitor the calories you eat daily?  None             no  \n",
            "12           How often do you have physical activity?  None             no  \n",
            "13  How much time do you use technological devices...  None             no  \n",
            "14                    How often do you drink alcohol?  None             no  \n",
            "15           Which transportation do you usually use?  None             no  \n",
            "16                                      Obesity level  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(X.dtypes)\n",
        "print(X.head())\n",
        "print(y.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-2v85gt9fXg",
        "outputId": "8ade67e5-b294-450a-b5e1-b3142c328ebe"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2111, 16)\n",
            "Gender                             object\n",
            "Age                               float64\n",
            "Height                            float64\n",
            "Weight                            float64\n",
            "family_history_with_overweight     object\n",
            "FAVC                               object\n",
            "FCVC                              float64\n",
            "NCP                               float64\n",
            "CAEC                               object\n",
            "SMOKE                              object\n",
            "CH2O                              float64\n",
            "SCC                                object\n",
            "FAF                               float64\n",
            "TUE                               float64\n",
            "CALC                               object\n",
            "MTRANS                             object\n",
            "dtype: object\n",
            "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
            "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
            "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
            "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
            "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
            "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
            "\n",
            "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
            "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
            "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
            "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
            "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
            "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
            "\n",
            "                  MTRANS  \n",
            "0  Public_Transportation  \n",
            "1  Public_Transportation  \n",
            "2  Public_Transportation  \n",
            "3                Walking  \n",
            "4  Public_Transportation  \n",
            "            NObeyesdad\n",
            "0        Normal_Weight\n",
            "1        Normal_Weight\n",
            "2        Normal_Weight\n",
            "3   Overweight_Level_I\n",
            "4  Overweight_Level_II\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleanup\n",
        "- Removing Duplicates\n",
        "- Encoding the Categorical Variables\n",
        "- handling missing values"
      ],
      "metadata": {
        "id": "uJj2Kfw7_0s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "I2QmvYuRBIkD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicates\n",
        "df = pd.concat([X, y],axis=1)\n",
        "df_cleaned = df.drop_duplicates(X)\n",
        "\n",
        "X = df_cleaned.drop(columns = y.columns)\n",
        "y = df_cleaned[y.columns]"
      ],
      "metadata": {
        "id": "iwPZrpzF97No"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of missing values in each column of X\n",
        "missing_X = X.isnull().sum()\n",
        "print(y.isnull().sum())\n",
        "\n",
        "\n",
        "# Display only columns with missing values\n",
        "print(missing_X[missing_X > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llADWybZBXdd",
        "outputId": "09476ff4-2ea5-4c04-9fd2-dc88d3a51e0c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NObeyesdad    0\n",
            "dtype: int64\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For a combined DataFrame df\n",
        "num_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = df_cleaned.select_dtypes(include=['object', 'category']).columns"
      ],
      "metadata": {
        "id": "eIiA3ypeB4KV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='mean')  # or strategy='median'\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "wnuOQj9jB_iF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical variables\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])"
      ],
      "metadata": {
        "id": "Ng0ukmQYCKoO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "MCGvoePNJKXO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "import joblib\n",
        "\n",
        "joblib.dump(cat_imputer, 'cat_imputer.pkl')\n",
        "joblib.dump(le, 'label_encoder_gender.pkl')  # one per column if needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sszCQn92JEKf",
        "outputId": "b4ab7955-7e8a-4f43-a80d-29af7bc0a2ac"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder_gender.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgYDMgE5JPhU",
        "outputId": "5896dab5-fa39-40a8-d801-243e248aff9a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2111 entries, 0 to 2110\n",
            "Data columns (total 17 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Gender                          2111 non-null   int64  \n",
            " 1   Age                             2111 non-null   float64\n",
            " 2   Height                          2111 non-null   float64\n",
            " 3   Weight                          2111 non-null   float64\n",
            " 4   family_history_with_overweight  2111 non-null   int64  \n",
            " 5   FAVC                            2111 non-null   int64  \n",
            " 6   FCVC                            2111 non-null   float64\n",
            " 7   NCP                             2111 non-null   float64\n",
            " 8   CAEC                            2111 non-null   int64  \n",
            " 9   SMOKE                           2111 non-null   int64  \n",
            " 10  CH2O                            2111 non-null   float64\n",
            " 11  SCC                             2111 non-null   int64  \n",
            " 12  FAF                             2111 non-null   float64\n",
            " 13  TUE                             2111 non-null   float64\n",
            " 14  CALC                            2111 non-null   int64  \n",
            " 15  MTRANS                          2111 non-null   int64  \n",
            " 16  NObeyesdad                      2111 non-null   int64  \n",
            "dtypes: float64(8), int64(9)\n",
            "memory usage: 280.5 KB\n",
            "None\n",
            "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
            "0       0  21.0    1.62    64.0                               1     0   2.0   \n",
            "1       0  21.0    1.52    56.0                               1     0   3.0   \n",
            "2       1  23.0    1.80    77.0                               1     0   2.0   \n",
            "3       1  27.0    1.80    87.0                               0     0   3.0   \n",
            "4       1  22.0    1.78    89.8                               0     0   2.0   \n",
            "\n",
            "   NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE  CALC  MTRANS  NObeyesdad  \n",
            "0  3.0     2      0   2.0    0  0.0  1.0     3       3           1  \n",
            "1  3.0     2      1   3.0    1  3.0  0.0     2       3           1  \n",
            "2  3.0     2      0   2.0    0  2.0  1.0     1       3           1  \n",
            "3  3.0     2      0   2.0    0  2.0  0.0     1       4           5  \n",
            "4  1.0     2      0   2.0    0  0.0  0.0     2       3           6  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "IE1tGojUNhUq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column                                                           | Type            | Encoding Strategy                    | Notes                              |\n",
        "| ---------------------------------------------------------------- | --------------- | ------------------------------------ | ---------------------------------- |\n",
        "| `Gender`                                                         | Binary          | Already Encoded (0=female, 1=male)   | ✅ Done                             |\n",
        "| `Age`, `Height`, `Weight`                                        | Numerical       | No encoding needed                   | Just scale later                   |\n",
        "| `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SCC` | Binary/Nominal  | Already Encoded                      | ✅ Done                             |\n",
        "| `FCVC`, `NCP`, `CH2O`, `FAF`, `TUE`, `CALC`                      | Ordinal/Numeric | Keep as is or ensure float → int     | Ordinal → can be scaled            |\n",
        "| `MTRANS`                                                         | Nominal         | Needs **One-Hot Encoding**           | Multi-class categorical, unordered |\n",
        "| `NObeyesdad`                                                     | Target          | Keep as **Label Encoded** if already | Multiclass target: fine as numeric |\n"
      ],
      "metadata": {
        "id": "CyBpSypyN2_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encode MTRANS properly\n",
        "df = pd.get_dummies(df, columns=['MTRANS'], prefix='MTRANS', drop_first=True)\n",
        "\n",
        "# Check the updated columns\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWDgVTxHOU_K",
        "outputId": "3d1fcda3-f2c5-40e5-c776-72ec1a9b584c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight',\n",
            "       'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE',\n",
            "       'CALC', 'NObeyesdad', 'MTRANS_1', 'MTRANS_2', 'MTRANS_3', 'MTRANS_4'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10NBIrvBOkTE",
        "outputId": "215f59bf-9f1c-4726-9ded-8b14eacc6f6d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2111 entries, 0 to 2110\n",
            "Data columns (total 20 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Gender                          2111 non-null   int64  \n",
            " 1   Age                             2111 non-null   float64\n",
            " 2   Height                          2111 non-null   float64\n",
            " 3   Weight                          2111 non-null   float64\n",
            " 4   family_history_with_overweight  2111 non-null   int64  \n",
            " 5   FAVC                            2111 non-null   int64  \n",
            " 6   FCVC                            2111 non-null   float64\n",
            " 7   NCP                             2111 non-null   float64\n",
            " 8   CAEC                            2111 non-null   int64  \n",
            " 9   SMOKE                           2111 non-null   int64  \n",
            " 10  CH2O                            2111 non-null   float64\n",
            " 11  SCC                             2111 non-null   int64  \n",
            " 12  FAF                             2111 non-null   float64\n",
            " 13  TUE                             2111 non-null   float64\n",
            " 14  CALC                            2111 non-null   int64  \n",
            " 15  NObeyesdad                      2111 non-null   int64  \n",
            " 16  MTRANS_1                        2111 non-null   bool   \n",
            " 17  MTRANS_2                        2111 non-null   bool   \n",
            " 18  MTRANS_3                        2111 non-null   bool   \n",
            " 19  MTRANS_4                        2111 non-null   bool   \n",
            "dtypes: bool(4), float64(8), int64(8)\n",
            "memory usage: 272.2 KB\n",
            "None\n",
            "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
            "0       0  21.0    1.62    64.0                               1     0   2.0   \n",
            "1       0  21.0    1.52    56.0                               1     0   3.0   \n",
            "2       1  23.0    1.80    77.0                               1     0   2.0   \n",
            "3       1  27.0    1.80    87.0                               0     0   3.0   \n",
            "4       1  22.0    1.78    89.8                               0     0   2.0   \n",
            "\n",
            "   NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE  CALC  NObeyesdad  MTRANS_1  \\\n",
            "0  3.0     2      0   2.0    0  0.0  1.0     3           1     False   \n",
            "1  3.0     2      1   3.0    1  3.0  0.0     2           1     False   \n",
            "2  3.0     2      0   2.0    0  2.0  1.0     1           1     False   \n",
            "3  3.0     2      0   2.0    0  2.0  0.0     1           5     False   \n",
            "4  1.0     2      0   2.0    0  0.0  0.0     2           6     False   \n",
            "\n",
            "   MTRANS_2  MTRANS_3  MTRANS_4  \n",
            "0     False      True     False  \n",
            "1     False      True     False  \n",
            "2     False      True     False  \n",
            "3     False     False      True  \n",
            "4     False      True     False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if we have all cleaned data\n",
        "print(df[[\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"CAEC\", \"SMOKE\", \"SCC\"]].dtypes)\n",
        "print(df[[\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"CAEC\", \"SMOKE\", \"SCC\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii8O0fVbP40y",
        "outputId": "e989ccfc-753d-4c72-ccbc-5567f4f4f6f0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender                            int64\n",
            "family_history_with_overweight    int64\n",
            "FAVC                              int64\n",
            "CAEC                              int64\n",
            "SMOKE                             int64\n",
            "SCC                               int64\n",
            "dtype: object\n",
            "   Gender  family_history_with_overweight  FAVC  CAEC  SMOKE  SCC\n",
            "0       0                               1     0     2      0    0\n",
            "1       0                               1     0     2      1    1\n",
            "2       1                               1     0     2      0    0\n",
            "3       1                               0     0     2      0    0\n",
            "4       1                               0     0     2      0    0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling & Train test split"
      ],
      "metadata": {
        "id": "YGfGmR4wOqVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "UI9sSyjQPHT3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Separate features and target\n",
        "X = df.drop(\"NObeyesdad\", axis=1)\n",
        "y = df[\"NObeyesdad\"]"
      ],
      "metadata": {
        "id": "58XzNx14PIOQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Zn0XMnfgPLbl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "qVfvkPhzPOKa"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR5EI403Pkf4",
        "outputId": "38f498b2-0fee-4c91-bc86-97f47c44873c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1688, 19)\n",
            "Test shape: (423, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training\n",
        "\n",
        "To choose best model I do stratified sampling where some strats are taken for each of the K fold cross validation"
      ],
      "metadata": {
        "id": "1ks6pKp-RjQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "ADIWwuGnQHHu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier()\n",
        "}\n"
      ],
      "metadata": {
        "id": "LcOla-nZR3Q_"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "    results[name] = scores\n",
        "    print(f\"{name}: Mean Accuracy = {scores.mean():.4f} | Std = {scores.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcY_kEy5R6HT",
        "outputId": "d6903742-2e33-4fc9-dd2d-e3a34b9081ad"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Mean Accuracy = 0.8679 | Std = 0.0150\n",
            "KNN: Mean Accuracy = 0.8016 | Std = 0.0138\n",
            "SVM: Mean Accuracy = 0.8578 | Std = 0.0099\n",
            "Random Forest: Mean Accuracy = 0.9490 | Std = 0.0081\n",
            "XGBoost: Mean Accuracy = 0.9704 | Std = 0.0068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model is Random Forest, XGBoost and SVM which has 94%, 97% and 85% accuracy"
      ],
      "metadata": {
        "id": "NUSc51JkSJfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper parameter tuning using Grid Search CV using the hyper parameters n_estimators, max_depth, min_samples_split"
      ],
      "metadata": {
        "id": "1meWSWW_STZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 1 - Random Forest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best RF Params:\", grid_rf.best_params_)\n",
        "print(\"Best RF Accuracy:\", grid_rf.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0XhyMnbSI5-",
        "outputId": "1f020cfd-8a80-4b33-c5e2-bda5fde30b6e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF Params: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Best RF Accuracy: 0.9520200867381876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 2 - SVM\n",
        "param_grid_svm = {\n",
        "    'C': [10, 11, 9],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best SVM Params:\", grid_svm.best_params_)\n",
        "print(\"Best SVM Accuracy:\", grid_svm.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPK_63uSxOy",
        "outputId": "18635a5c-7715-47d7-c7a8-d9cd308b9595"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Params: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best SVM Accuracy: 0.960307622074342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xgboost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 1],\n",
        "    'reg_lambda': [1, 10]  # L2 regularization\n",
        "}\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "grid_xgb = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid_xgb,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"✅ Best Parameters:\", grid_xgb.best_params_)\n",
        "print(\"🏆 Best CV Accuracy:\", grid_xgb.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DajLdsZUUGG",
        "outputId": "afddc147-910c-49b1-a574-a88f54267a87"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:30:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Best Parameters: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'reg_lambda': 1, 'subsample': 1.0}\n",
            "🏆 Best CV Accuracy: 0.9697803451969168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#best_model = grid_rf.best_estimator_\n",
        "best_model =  grid_svm.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuR9ZFFmTGPS",
        "outputId": "484f43d2-eeea-4a32-c0d1-24fec90cf79d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[54  0  0  0  0  0  0]\n",
            " [ 3 53  0  0  0  2  0]\n",
            " [ 0  0 67  1  0  0  2]\n",
            " [ 0  0  0 60  0  0  0]\n",
            " [ 0  0  0  1 64  0  0]\n",
            " [ 0  1  0  0  0 56  1]\n",
            " [ 0  0  2  0  0  4 52]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97        54\n",
            "           1       0.98      0.91      0.95        58\n",
            "           2       0.97      0.96      0.96        70\n",
            "           3       0.97      1.00      0.98        60\n",
            "           4       1.00      0.98      0.99        65\n",
            "           5       0.90      0.97      0.93        58\n",
            "           6       0.95      0.90      0.92        58\n",
            "\n",
            "    accuracy                           0.96       423\n",
            "   macro avg       0.96      0.96      0.96       423\n",
            "weighted avg       0.96      0.96      0.96       423\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating Xgboost\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "\n",
        "print(\"📊 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "print(\"\\n📝 Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ6gopLnUjv2",
        "outputId": "033c5b65-2172-413e-f8df-8b548758fe99"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Confusion Matrix:\n",
            " [[49  5  0  0  0  0  0]\n",
            " [ 4 53  0  0  0  1  0]\n",
            " [ 0  0 69  0  0  0  1]\n",
            " [ 0  0  1 59  0  0  0]\n",
            " [ 0  0  1  0 64  0  0]\n",
            " [ 0  5  0  0  0 53  0]\n",
            " [ 0  0  1  0  0  1 56]]\n",
            "\n",
            "📝 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.92        54\n",
            "           1       0.84      0.91      0.88        58\n",
            "           2       0.96      0.99      0.97        70\n",
            "           3       1.00      0.98      0.99        60\n",
            "           4       1.00      0.98      0.99        65\n",
            "           5       0.96      0.91      0.94        58\n",
            "           6       0.98      0.97      0.97        58\n",
            "\n",
            "    accuracy                           0.95       423\n",
            "   macro avg       0.95      0.95      0.95       423\n",
            "weighted avg       0.95      0.95      0.95       423\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAving the model that is best"
      ],
      "metadata": {
        "id": "liBkkeNrVP1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb9UaBKYVK0Y",
        "outputId": "c812ab57-d5ec-4dcf-b2df-3801167e1fec"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the model to predict"
      ],
      "metadata": {
        "id": "QicQCBmMVRym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved model\n",
        "model = joblib.load('best_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# New sample input (replace with real input)\n",
        "new_data = pd.DataFrame([[1, 25, 1.70, 65, 1, 1, 2.0, 3.0, 1, 0, 2.0, 1, 2.0, 1.0, 2] + [0]*N])  # replace N with MTRANS one-hot features count\n",
        "\n",
        "# Scale\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(new_data_scaled)\n",
        "print(\"Predicted class:\", prediction[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "-tDN4ew3VUWo",
        "outputId": "35c30dc3-2bdf-4656-bfe7-131a0c25fff7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'N' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-3768163630>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# New sample input (replace with real input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# replace N with MTRANS one-hot features count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEploying the model using flask"
      ],
      "metadata": {
        "id": "hBF06eWKVZJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = joblib.load('best_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    input_data = request.get_json(force=True)\n",
        "    features = np.array(input_data['features']).reshape(1, -1)\n",
        "    features_scaled = scaler.transform(features)\n",
        "    prediction = model.predict(features_scaled)\n",
        "    return jsonify({'prediction': int(prediction[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "LmfvmSakVbF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}